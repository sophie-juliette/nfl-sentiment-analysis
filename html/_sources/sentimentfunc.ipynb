{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment.py-File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId\n",
    "from googleapiclient.discovery import build\n",
    "from google.cloud import language_v1\n",
    "\n",
    "def get_entity_sentiment(myText):\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "    doc = language_v1.Document(content=myText,type_=language_v1.types.Document.Type.PLAIN_TEXT)\n",
    "    response = client.analyze_entity_sentiment(request={'document':doc, 'encoding_type':language_v1.EncodingType.UTF8})\n",
    "    myList = list()\n",
    "    for ent in response.entities:\n",
    "        myDict = dict()\n",
    "        sent = ent.sentiment \n",
    "        myDict['entity'] = ent.name\n",
    "        myDict['salience'] = ent.salience\n",
    "        myDict['score'] = sent.score\n",
    "        myDict['magnitude'] = sent.magnitude\n",
    "        myList.append(myDict)\n",
    "    return myList\n",
    "\n",
    "def get_videoID_by_title(video_title):\n",
    "    '''\n",
    "    takes: video_title as string\n",
    "    returns: videoId as string\n",
    "    describtion:\n",
    "        builds a connection to Youtube Data API and executes a search method to list results.\n",
    "        searches for channelId from NFL-Youtube Channel, for videos only\n",
    "        returns videoID for most relevant search result\n",
    "    '''\n",
    "    try:\n",
    "        youtube = build('youtube', 'v3', \n",
    "                    developerKey=api_key)\n",
    "        response = youtube.search().list(\n",
    "        \t        part='snippet',\n",
    "                \tq=video_title,\n",
    "                \tchannelId='UCDVYQ4Zhbm3S2dlz7P1GBDg', # NFL Channel ID\n",
    "                \ttype='video',\n",
    "                \torder='relevance', # Default Value = relevance\n",
    "                \tmaxResults=1\n",
    "                \t).execute()\n",
    "        return response['items'][-1]['id']['videoId']\n",
    "    except:\n",
    "        return \"NoQuota\"\n",
    "\n",
    "def get_comments(vidId):\n",
    "    '''\n",
    "    takes: youtube video id as string, global api_key as string\n",
    "    returns: list of toplevel-comments under video (no replies)\n",
    "    describtion:\n",
    "        builds a connection to Youtube Data API and executs commentsThreads().list() methods\n",
    "        iterates over response from api request and stores displayed text as string in an list\n",
    "        breaks if no NextPageToken is provided. Thus end of comments is reached.\n",
    "        breaks if counter < threshold-value prevent Youtube out of quota error\n",
    "        returns list with comments\n",
    "    '''\n",
    "    # list for several pages\n",
    "    comments = list()\n",
    "    counter = 4\n",
    "\n",
    "    # get youtube access\n",
    "    youtube = build('youtube', 'v3', \n",
    "                developerKey=api_key)\n",
    "    print('yt loaded')\n",
    "    # get response\n",
    "    response = youtube.commentThreads().list(\n",
    "\t            part='snippet',\n",
    "\t            videoId=vidId,\n",
    "                textFormat='plainText'\n",
    "\t            ).execute()\n",
    "\n",
    "    while True:\n",
    "        for item in response['items']:\n",
    "            # get comment as string, attached to list.\n",
    "            # return item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "            comments.append(item['snippet']['topLevelComment']['snippet']['textDisplay'])\n",
    "        counter -=1\n",
    "        if counter < 1:\n",
    "             break\n",
    "        if 'nextPageToken' in response:\n",
    "            response = youtube.commentThreads().list(\n",
    "\t                    part='snippet',\n",
    "                        pageToken=response['nextPageToken'],\n",
    "\t                    videoId=vidId\n",
    "\t                    ).execute()\n",
    "        else:\n",
    "            break\n",
    "    print('comments returned')\n",
    "    return comments\n",
    "\n",
    "\n",
    "api_key = json.load(open('API_Data.json'))['ytDataAPI'] # key for Youtube Data API\n",
    "mongodb_pass = json.load(open('API_Data.json'))['mongoDB_pass'] # password mongodb user\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"green-reporter-369217-84ed773093b1.json\" # expose google service account for sentiment analysis\n",
    "\n",
    "client = MongoClient(mongodb_pass)\n",
    "db = client.gc_nfl\n",
    "mycoll = db.gc_games\n",
    "# db = client.nfl_data\n",
    "# mycoll = db.games\n",
    "\n",
    "myList = mycoll.find({'videoID':{'$exists':False}})[0:2]\n",
    "for doc in myList:\n",
    "    mongo_obj_id = doc['_id'] # ObjectID von mongoDB speichern\n",
    "    myTitle = doc['team1']+' '+doc['team2']+' '+doc['week']+' Highlights | NFL 2021'\n",
    "    vid_id = get_videoID_by_title(myTitle)\n",
    "    if vid_id == \"NoQuota\":\n",
    "        print(vid_id)\n",
    "        break\n",
    "    print(myTitle)\n",
    "    comment_count = 0\n",
    "    for comment in get_comments(vid_id):\n",
    "        comment_count += 1\n",
    "        myDict = dict()\n",
    "        # Retrieve old information\n",
    "        myDict = doc\n",
    "        myDict['videoID'] = vid_id\n",
    "\n",
    "        # Add new information / generate one doc per entity\n",
    "        myDict['comment'] = comment\n",
    "\n",
    "        try:\n",
    "            entList = get_entity_sentiment(comment)\n",
    "            count = 0 \n",
    "            for ent in entList:\n",
    "                count+=1\n",
    "                print('next Dict',count) \n",
    "                del myDict['_id']\n",
    "                myDict['entity'] = ent['entity']\n",
    "                myDict['salience'] = ent['salience']\n",
    "                myDict['score'] = ent['score']\n",
    "                myDict['magnitude'] = ent['magnitude']\n",
    "                mycoll.insert_one(myDict)\n",
    "        except:\n",
    "            print('Comment is not in English.')\n",
    "        print('next comment',comment_count)\n",
    "    # mycoll.delete_one({'_id':mongo_obj_id})\n",
    "    print('delete document')\n",
    "    mycoll.delete_one({'_id':ObjectId(mongo_obj_id)})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b8dfdb05e476a0fb0e450349f9b76abd6ac1559882404eeba22108e759c936b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
